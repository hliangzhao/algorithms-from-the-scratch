//
// Created by hliangzhao on 25/1/23.
//
#include <iostream>
#include <map>
#include <random>

using namespace std;

/**
 * 要点：理解哈希函数和哈希表的实现（常常用于大数据相关岗位的面试）
 *
 * 1、哈希函数：y = f(x), x 可以取任何值，但是值域是一个有界的范围
 * （1）不含有随机成分，同一个输入必然得到同一个输出。
 * （2）不同的输入，可能会导致相同的输出（哈希碰撞），但概率极低。越低越好。
 * （3）哈希函数可以从期望上保证任意输入映射到值域上时，满足均匀分布，这意味着哈希函数内部时无规律的（离散性/均匀性）。
 *
 * 2、哈希表的实现
 * 申请一个大小为 SIZE 的指针数组，每个原始是一个指向链表的指针。
 * 对于每个传入的 {key, value}，带入一个内部的哈希函数计算得到 y，然后将该键值对链接到以 y % SIZE 作为 index 的元素所指向的链表末尾。
 * 键值对的查询也遵循类似的步骤。可以规定一个链表最大长度，当存在一个（或很多，看具体实现）链表长度都超过该最大长度时，
 * 申请扩容（SIZE 翻倍），然后 rehash。
 *
 * 基于上述设计，可以保证不扩容时，插入、查询键值对到哈希表中的复杂度都几乎为 O(1)。
 * 此外，扩容的次数为 O(log n)，单次扩容后，rehash 的代价是 O(n)。
 * 因此，整体上，查询/插入键值对的代价平均为 O(n * log n / n)。但是，如果哈希表一开始的 SIZE 开得较大，且其扩容由 runtime
 * 在后台用户无感式完成，则可以认为存取的速度为 O(1)。
 *
 * 哈希函数常常被用来对大数据进行分流。
 * */

/**
 * 题目一：给定一个包含 40 亿个无符号整数（范围 0 ～ 约 42 亿）的文件和 1G 内存，要求返回出现次数最多的数。
 *
 * 解：使用哈希函数。
 * 将每个数 x 传入某个哈希函数得到 y，再将 y % 100。根据该结果将 x 分发至编号为 y % 100 的文件中。
 * 根据哈希函数的随机性，这 100 个文件内包含的数的数量应当几乎相同，依次检查每个文件中出现次数最多的数（使用 map<int, int>），
 * 再将结果合并即可。处理每个文件仅需要 0.25 亿 * 8 Bytes = 2 亿 < 10 亿 ～ 1 GB。依次进行是可行的。
 *
 * 使用哈希函数既可以保证同一个数只会出现在一个文件中，这使得合并解的时候很方便；又能减少内存占用。
 * */

/**
 * 题目二：设计 RandomPool 结构，要求：
 * （1）insert(key)：做到不重复加入；
 * （2）delete(key)：删除；
 * （3）get_random()：等概率返回任意一个key。
 * 要求三个操作的时间复杂度都是 O(1)。
 *
 * 不是要你自己实现 C++ 内部的 hash se，借助它们实现即可。
 * */

/**
 * 维护两张哈希表，每次删除元素时，把最后一个元素填充到被删除元素的位置（修改对应的 index），从而保证随机时不出现空位。
 * */
template<typename key_type>
struct RandomPool {
    map<key_type, int> key2idx;
    map<int, key_type> idx2key;
    int size{0};
};

template<typename key_type>
void insert(RandomPool<key_type> *pool, key_type key) {
    if (pool->key2idx.find(key) == pool->key2idx.end()) {
        pool->key2idx.insert({key, pool->size});
        pool->idx2key.insert({pool->size++, key});
    }
}

template<typename key_type>
void del(RandomPool<key_type> *pool, key_type key) {
    if (pool->key2idx.find(key) != pool->key2idx.end()) {
        int del_idx = pool->key2idx[key];
        int last_idx = --pool->size;
        key_type last_key = pool->idx2key[last_idx];

        pool->key2idx[last_key] = del_idx;
        pool->idx2key[del_idx] = last_key;

        pool->key2idx.erase(key);
        pool->idx2key.erase(last_idx);
    }
}

template<typename key_type>
key_type get_random(RandomPool<key_type> *pool) {
    if (pool->size == 0) {
        return nullptr;
    }

    ::random_device rd;
    ::mt19937 mt(rd());
    int *arr = new int[pool->size];
    uniform_int_distribution<int> rand_distribution(0, pool->size);
    return pool->idx2key[rand_distribution(mt)];
}

/**
 * 题目三：32 位无符号整数的范围约为 0～43 亿。现有一个包含 40 亿个无符号整数的文件，所以在整个范围中必然存在没出现的数。
 * 要求最多使用 1GB 的内存，怎样找到所有没出现的数？如何内存限制为 3KB，但是只需要找到一个没出现的数，怎么做？
 * 如果只能申请有限的几个整型变量，怎么找到至少一个没出现的数？
 *
 * */

/**
 * 对于子问题一：申请一个大小为 (2^32 - 1)/8 Bytes（约为 500 MB）的字节数组，用每一位为 1 或 0 表示对应的数字是否出现过。
 * */

/**
 * 对于子问题二：申请一个大小为 512 的整型数组 cnt（4*512 = 2^11 < 3000 Bytes），将无符号整型范围内的数划分为 512 份，
 * 每一份包含 2^23 个数。第一份包含数字 0 ～ 2^23-1，第二份包含 2^23 ~ 2^24-1，等等。
 * 依次遍历 40 亿个数，将每个数所属区间（不妨记为 idx）的统计值++，即 cnt[idx]++。
 * 显然，必然存在至少一个区间 cnt 值 < 2^23。任选其中一个区间，将内部的数继续划分为 512 个区间，并重复上述步骤。
 * 如此反复，必然可以找到某个不在本文件中的数。
 * */

/**
 * 对于子问题三：二分即可。假设只能申请两个变量，分别表示左半部分和右半部分的数字个数。
 * 一开始，将 0 ~ 2^32-1 对半切分，遍历每个数统计两个部分的词频，找到 <2^31 的那个区间，在本区间上二分，如此反复。
 *
 * 对本问题的总结：位图可以被用来解决某一范围上数字的出现情况，并节省大量空间。位图还可以结合分段统计的思想，进一步节省空间占用。
 * */

/**
 * 题目四：给一个包含 100 亿个 URL 的大文件。假设每个 URL 占 64 B，找出其中所有重复的 URL。
 *
 * 方法一：和题目一的处理方式一样。
 *
 * 方法二：使用堆。一开始的步骤和方法一一样，使用哈希函数将这些 URL 映射到多个小文件中。
 * 接下来，分别统计每个小文件中 URL 的词频。具体地，每个小文件对应一个大根堆，堆顶存放的是当前小文件中出现次数最多的 URL。
 * 随后，我们建立一个全局大根堆，并将各个小文件大根堆的堆顶元素放入全局大根堆中。
 * 接下来，依次弹出全局大根堆的堆顶元素，找到这个元素所在的小文件大根堆，弹出这个小文件大根堆的堆顶，并将新的堆顶插入全局大根堆中。
 * 如此反复，直到全局大根堆弹空。
 *
 * 对本问题的总结：可以利用堆来做多个处理单元结果的合并。
 * */

/**
 * 题目五：32 位无符号整数的范围约为 0～43 亿。现有一个包含 40 亿个无符号整数的文件。在最多使用 1GB 左右内存的前提下，
 * 找出所有出现了两次的数。
 *
 * 方法一：和题目一的处理方式一样。使用哈希函数分流，分别统计每个小文件中出现了两次的数，最后将结果合并。
 *
 * 方法二：每个数出现的次数用两位来记录。对于任意数，00 表示出现零次，01 表示出现一次，10 表示出现两次，11 表示出现三次及以上。
 * 对于 2^32 个数，一共需要 2^32*2/8（约为 1.073741824 GB）字节，刚好基本满足。
 *
 * 对本问题的总结：位图并不意味着一定只能使用一个 bit。使用多个 bit，可以编码的状态就更多，这取决于具体问题的需要。
 * */

/**
 * 题目六：32 位无符号整数的范围约为 0～43 亿。现有一个包含 40 亿个无符号整数的文件。
 * 如果最多允许使用 10KB 内存，怎么找到这些数的中位数？
 *
 * 方法：和题目三的子问题二的处理方式一样。10KB 内存，最多申请大小为 2500 的无符号整数数组，因此最近的、可能被 2 整除的大小为
 * 2048 = 2^12。因此，我们申请大小为 2048 的无符号整型数组 cnt，每个位置依次对应 0 ～ 2^20 - 1，2^20 ～ 2^21 - 1 这些区间。
 * 依次遍历 40 亿数中的每一个，将其所在的区间 cnt 值++。
 * 接下来，我们遍历该数组，并将前序和存入 res 中。找到使用 res < 20 亿、res + cnt[idx] > 20 亿的那个区间 idx。
 * 接下来，将这个区间继续等分为 2048 份，然后找到使得 \sum_{i < idx} cnt[i] + res < 20 亿、\sum_{i < idx} cnt[i] + res + cnt[idx'] > 20 亿
 * 的那个区间 idx'。如此反复，直到我们找到中位数。
 * */

/**
 * 题目七：给定一个大小为 10G 的文件，每行存放一个 int 类型的数据。
 * 给定 5GB 内存，将这些数据输出到一个新文件中，要求这些数据在新文件中有序。
 *
 * 方法一：分桶 + 小根堆。建立一个小根堆，堆内元素是一个结构体，含有两个 int 字段：数和本数出现的次数。因此，一个元素占 8 字节。
 * 为了充分考虑鲁棒性，不妨给每个元素开 16 字节的空间。这意味着，5GB 内存可以建立一个大小为 5*10^9/2^4 \approx 5*2^30/2^4 = 5*2^26。
 * 取最近的、可以被 2 整除的数字，即 4*2^26 = 2^28。
 * 因此，我们开一个最大范围为 2^28 的小根堆。并将全部 int 数字划分到 2^32 / 2^28 = 16 个区间。第一个区间对应范围 -2^31 ～ -2^31+2^28-1，
 * 第二个区间对应 -2^31+2^28 ～ -2^31+2^29-1，以此类推。接下来，依次堆每个区间执行如下操作：
 * 建立对应的小根堆，然后遍历文件中的每个数字，如果该数字属于本区间，对应词频++并更新小根堆。最后，将该小根堆堆顶元素依次弹出并写入新文件中。
 * 对所有 16 个区间均执行如上操作，每次只需要把弹出的元素 append 到新文件末尾即可，如此便解决了此问题。
 *
 * 方法二：不分桶，但是建立门槛不断变化的大根堆，大根堆内存放的元素仍然是包含两个 int 字段的（数和本数出现的次数）的结构体实例。
 * 例如，开一个最多存放 500 个元素的大根堆。接下来遍历文件中的所有数，在保证大根堆内元素不超过 500 的前提下，
 * 我们就能找到全文件最小的、至少 500 个数（不少于是因为有些数可能重复）。记录堆顶元素值为 x，将这些数依次逆序后写入文件。
 * 接下来，以 x 作为门槛，遍历全体文件，在不爆堆的前提下，把 <=x 的数放入大根堆，然后同样逆序写入新文件。
 * 如此反复，直到某次遍历大根堆中没任何新元素进入。
 * 该方法在极限情况下，只需要两次文件遍历即可（第一次就找到全部的数，第二次堆为空）。
 * */

int main() {
    return 0;
}